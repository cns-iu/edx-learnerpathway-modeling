{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, Embedding, Reshape, Multiply\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from data_parsing import load_trajectories\n",
    "from functools import partial, reduce\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "# from glob import glob\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trajectories, status = load_trajectories('data/MITxPRO+AMxB+1T2018/edges', 'data/MITxPRO+AMxB+1T2018/MITxPRO-AMxB-1T2018-auth_user-students.csv')\n",
    "trajectories, status = load_trajectories('data/MITxPRO+LASERxB1+1T2019/LaaL', 'data/MITxPRO+LASERxB1+1T2019/MITxPRO-LASERxB1-1T2019-auth_user-students.csv')\n",
    "#trajectories = load_trajectories('data/MITxPRO+LASERxB1+1T2019/LaaL')\n",
    "#id_and_performance = pd.read_csv('data/MITxPRO-AMxB-1T2018/MITxPRO-AMxB-1T2018-auth_user-students.csv')\n",
    "#id_and_performance = pd.read_csv('data/MITxPRO+AMxB+1T2018/MITxPRO-AMxB-1T2018-auth_user-students.csv')\n",
    "#id_and_performance.iloc[0]\n",
    "#id_and_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AM_modules = pd.read_csv('data/MITxPRO+AMxB+1T2018/MITxPRO+AMxB+1T2018-modules.txt', sep='\\t', encoding='utf-16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum trajectory identified by number of clicks:  1699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count of students')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "traj_lengths = trajectories.map(len).values\n",
    "plt.hist(traj_lengths)\n",
    "print(\"Maximum trajectory identified by number of clicks: \", max(traj_lengths))\n",
    "plt.title('AM course')\n",
    "plt.xlabel('Learner trajectory length identified by number of clicks')\n",
    "plt.ylabel('Count of students')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data generators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06190476190476191"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = np.arange(len(trajectories))\n",
    "np.random.seed(9)\n",
    "np.random.shuffle(index)\n",
    "\n",
    "incoming_traj = []\n",
    "outgoing_traj = []\n",
    "\n",
    "# this split assumes that we don't need to rebalance for unequal category weights\n",
    "n_valid = int(2*np.sqrt(len(trajectories)))\n",
    "n_train = len(trajectories) - n_valid\n",
    "success_rate = status[index[:n_train]].sum() / n_train\n",
    "\n",
    "for traj in trajectories.values:\n",
    "    incoming_traj.append(np.array(traj[:-1]).reshape(1,-1))\n",
    "    outgoing_traj.append(np.array(traj[1:]).reshape(-1,1))\n",
    "\n",
    "def data_generator(start, stop, use_status):\n",
    "     while True:\n",
    "        for i in range(start, stop):        \n",
    "            x = incoming_traj[index[i]].reshape(1,-1)\n",
    "            s = np.broadcast_to(status[index[i]], x.shape)\n",
    "            y = outgoing_traj[index[i]].reshape(1,-1)\n",
    "            if use_status:\n",
    "                yield [x,s],y\n",
    "            else:\n",
    "                yield x,y\n",
    "\n",
    "train_generator_simp = partial(data_generator, 0, n_train, False)\n",
    "valid_generator_simp = partial(data_generator, n_train, n_train+n_valid, False)\n",
    "train_generator_cond = partial(data_generator, 0, n_train, True)\n",
    "valid_generator_cond = partial(data_generator, n_train, n_train+n_valid, True)\n",
    "success_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 37\n",
    "embedding_dim = 30\n",
    "# turning trajectories into sets of URLs\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "number_of_URL = max(trajectories.sum()) + 1\n",
    "#number_of_URL = 1121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Simple_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "history (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "URL_embedding (Embedding)    (None, None, 30)          13980     \n",
      "_________________________________________________________________\n",
      "LSTM (LSTM)                  (None, None, 37)          10064     \n",
      "_________________________________________________________________\n",
      "Predicted_URL (Dense)        (None, None, 466)         17708     \n",
      "=================================================================\n",
      "Total params: 41,752\n",
      "Trainable params: 41,752\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_ = Input(shape=(None,), name='history')\n",
    "embed = Embedding(number_of_URL, embedding_dim, name='URL_embedding')(input_)\n",
    "\n",
    "rnn = LSTM(hidden_dim, return_sequences=True, name='LSTM')(embed)\n",
    "\n",
    "predicted_URL = Dense(number_of_URL, activation = 'softmax', name='Predicted_URL')(rnn)\n",
    "\n",
    "model_simp = Model(inputs=input_, outputs=predicted_URL, name='Simple_model')\n",
    "model_simp.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "model_simp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conditional_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "history (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "URL_embedding (Embedding)       (None, None, 30)     13980       history[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "status (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "LSTM (LSTM)                     (None, None, 37)     10064       URL_embedding[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Status_embedding (Embedding)    (None, None, 37)     74          status[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, None, 37)     0           LSTM[0][0]                       \n",
      "                                                                 Status_embedding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Predicted_URL (Dense)           (None, None, 466)    17708       multiply[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 41,826\n",
      "Trainable params: 41,826\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_x = Input(shape=(None,), name='history')\n",
    "input_s = Input(shape=(None,), name='status')\n",
    "embed_x = Embedding(number_of_URL, embedding_dim, name='URL_embedding')(input_x)\n",
    "embed_s = Embedding(2, hidden_dim, embeddings_initializer='ones', name='Status_embedding')(input_s)\n",
    "\n",
    "rnn = LSTM(hidden_dim, return_sequences=True, name='LSTM')(embed_x)\n",
    "masked = Multiply()([rnn, embed_s])\n",
    "\n",
    "predicted_URL = Dense(number_of_URL, activation = 'softmax', name='Predicted_URL')(masked)\n",
    "\n",
    "model_cond = Model(inputs=[input_x, input_s], outputs=predicted_URL, name='Conditional_model')\n",
    "model_cond.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "model_cond.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_simp.load_weights('weights_simp.h5')\n",
    "#model_cond.load_weights('LaaL_cond_hiddim30-.hdf5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-10fec44ce33f>:10: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 210 steps, validate for 31 steps\n",
      "Epoch 1/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 5.6547 - acc: 0.0187\n",
      "Epoch 00001: val_loss improved from inf to 5.30203, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 54s 255ms/step - loss: 5.6532 - acc: 0.0187 - val_loss: 5.3020 - val_acc: 0.0319\n",
      "Epoch 2/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 4.8569 - acc: 0.0518\n",
      "Epoch 00002: val_loss improved from 5.30203 to 4.50168, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 50s 239ms/step - loss: 4.8551 - acc: 0.0520 - val_loss: 4.5017 - val_acc: 0.0839\n",
      "Epoch 3/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 4.0718 - acc: 0.1099\n",
      "Epoch 00003: val_loss improved from 4.50168 to 3.71655, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 50s 236ms/step - loss: 4.0699 - acc: 0.1103 - val_loss: 3.7166 - val_acc: 0.1548\n",
      "Epoch 4/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 3.3478 - acc: 0.2214\n",
      "Epoch 00004: val_loss improved from 3.71655 to 3.07887, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 49s 236ms/step - loss: 3.3464 - acc: 0.2219 - val_loss: 3.0789 - val_acc: 0.2814\n",
      "Epoch 5/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 2.8012 - acc: 0.3245\n",
      "Epoch 00005: val_loss improved from 3.07887 to 2.61144, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 49s 235ms/step - loss: 2.8002 - acc: 0.3247 - val_loss: 2.6114 - val_acc: 0.3621\n",
      "Epoch 6/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 2.4156 - acc: 0.3984\n",
      "Epoch 00006: val_loss improved from 2.61144 to 2.29342, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 49s 234ms/step - loss: 2.4151 - acc: 0.3985 - val_loss: 2.2934 - val_acc: 0.4226\n",
      "Epoch 7/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 2.1459 - acc: 0.4547\n",
      "Epoch 00007: val_loss improved from 2.29342 to 2.06924, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 49s 235ms/step - loss: 2.1457 - acc: 0.4547 - val_loss: 2.0692 - val_acc: 0.4795\n",
      "Epoch 8/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.9503 - acc: 0.5010\n",
      "Epoch 00008: val_loss improved from 2.06924 to 1.90776, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 49s 235ms/step - loss: 1.9503 - acc: 0.5008 - val_loss: 1.9078 - val_acc: 0.5167\n",
      "Epoch 9/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.8079 - acc: 0.5320\n",
      "Epoch 00009: val_loss improved from 1.90776 to 1.79065, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 49s 234ms/step - loss: 1.8080 - acc: 0.5319 - val_loss: 1.7906 - val_acc: 0.5448\n",
      "Epoch 10/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.7012 - acc: 0.5554\n",
      "Epoch 00010: val_loss improved from 1.79065 to 1.70233, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 49s 235ms/step - loss: 1.7015 - acc: 0.5552 - val_loss: 1.7023 - val_acc: 0.5658\n",
      "Epoch 11/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.6184 - acc: 0.5726\n",
      "Epoch 00011: val_loss improved from 1.70233 to 1.63376, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 50s 236ms/step - loss: 1.6187 - acc: 0.5724 - val_loss: 1.6338 - val_acc: 0.5767\n",
      "Epoch 12/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.5526 - acc: 0.5845\n",
      "Epoch 00012: val_loss improved from 1.63376 to 1.57958, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 49s 235ms/step - loss: 1.5530 - acc: 0.5843 - val_loss: 1.5796 - val_acc: 0.5855\n",
      "Epoch 13/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.4992 - acc: 0.5946\n",
      "Epoch 00013: val_loss improved from 1.57958 to 1.53533, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 49s 235ms/step - loss: 1.4995 - acc: 0.5944 - val_loss: 1.5353 - val_acc: 0.5955\n",
      "Epoch 14/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.4547 - acc: 0.6025\n",
      "Epoch 00014: val_loss improved from 1.53533 to 1.49854, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 49s 235ms/step - loss: 1.4551 - acc: 0.6023 - val_loss: 1.4985 - val_acc: 0.6020\n",
      "Epoch 15/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.4171 - acc: 0.6097\n",
      "Epoch 00015: val_loss improved from 1.49854 to 1.46747, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 49s 234ms/step - loss: 1.4176 - acc: 0.6095 - val_loss: 1.4675 - val_acc: 0.6092\n",
      "Epoch 16/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.3850 - acc: 0.6166\n",
      "Epoch 00016: val_loss improved from 1.46747 to 1.44084, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 49s 236ms/step - loss: 1.3855 - acc: 0.6164 - val_loss: 1.4408 - val_acc: 0.6158\n",
      "Epoch 17/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.3571 - acc: 0.6224\n",
      "Epoch 00017: val_loss improved from 1.44084 to 1.41780, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 49s 235ms/step - loss: 1.3576 - acc: 0.6222 - val_loss: 1.4178 - val_acc: 0.6218\n",
      "Epoch 18/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.3325 - acc: 0.6279\n",
      "Epoch 00018: val_loss improved from 1.41780 to 1.39763, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 49s 235ms/step - loss: 1.3330 - acc: 0.6277 - val_loss: 1.3976 - val_acc: 0.6263\n",
      "Epoch 19/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.3106 - acc: 0.6324\n",
      "Epoch 00019: val_loss improved from 1.39763 to 1.38000, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 49s 235ms/step - loss: 1.3111 - acc: 0.6321 - val_loss: 1.3800 - val_acc: 0.6298\n",
      "Epoch 20/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.2912 - acc: 0.6363\n",
      "Epoch 00020: val_loss improved from 1.38000 to 1.36466, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 52s 249ms/step - loss: 1.2917 - acc: 0.6361 - val_loss: 1.3647 - val_acc: 0.6338\n",
      "Epoch 21/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.2739 - acc: 0.6395\n",
      "Epoch 00021: val_loss improved from 1.36466 to 1.35113, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 50s 237ms/step - loss: 1.2744 - acc: 0.6392 - val_loss: 1.3511 - val_acc: 0.6376\n",
      "Epoch 22/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.2583 - acc: 0.6428\n",
      "Epoch 00022: val_loss improved from 1.35113 to 1.33922, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 49s 235ms/step - loss: 1.2589 - acc: 0.6426 - val_loss: 1.3392 - val_acc: 0.6407\n",
      "Epoch 23/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.2444 - acc: 0.6450\n",
      "Epoch 00023: val_loss improved from 1.33922 to 1.32871, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 49s 235ms/step - loss: 1.2450 - acc: 0.6448 - val_loss: 1.3287 - val_acc: 0.6432\n",
      "Epoch 24/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.2316 - acc: 0.6474\n",
      "Epoch 00024: val_loss improved from 1.32871 to 1.31952, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 49s 235ms/step - loss: 1.2322 - acc: 0.6472 - val_loss: 1.3195 - val_acc: 0.6449\n",
      "Epoch 25/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.2200 - acc: 0.6498\n",
      "Epoch 00025: val_loss improved from 1.31952 to 1.31089, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 49s 235ms/step - loss: 1.2206 - acc: 0.6496 - val_loss: 1.3109 - val_acc: 0.6481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.2093 - acc: 0.6521\n",
      "Epoch 00026: val_loss improved from 1.31089 to 1.30313, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 49s 232ms/step - loss: 1.2099 - acc: 0.6519 - val_loss: 1.3031 - val_acc: 0.6497\n",
      "Epoch 27/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.1994 - acc: 0.6544\n",
      "Epoch 00027: val_loss improved from 1.30313 to 1.29610, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 49s 232ms/step - loss: 1.2000 - acc: 0.6542 - val_loss: 1.2961 - val_acc: 0.6511\n",
      "Epoch 28/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.1901 - acc: 0.6561\n",
      "Epoch 00028: val_loss improved from 1.29610 to 1.28989, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 49s 233ms/step - loss: 1.1907 - acc: 0.6560 - val_loss: 1.2899 - val_acc: 0.6520\n",
      "Epoch 29/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.1815 - acc: 0.6575\n",
      "Epoch 00029: val_loss improved from 1.28989 to 1.28415, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 54s 255ms/step - loss: 1.1821 - acc: 0.6573 - val_loss: 1.2842 - val_acc: 0.6529\n",
      "Epoch 30/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.1734 - acc: 0.6589\n",
      "Epoch 00030: val_loss improved from 1.28415 to 1.27888, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 50s 238ms/step - loss: 1.1740 - acc: 0.6587 - val_loss: 1.2789 - val_acc: 0.6545\n",
      "Epoch 31/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.1658 - acc: 0.6604\n",
      "Epoch 00031: val_loss improved from 1.27888 to 1.27402, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 51s 244ms/step - loss: 1.1664 - acc: 0.6603 - val_loss: 1.2740 - val_acc: 0.6554\n",
      "Epoch 32/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.1587 - acc: 0.6621\n",
      "Epoch 00032: val_loss improved from 1.27402 to 1.26958, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 52s 246ms/step - loss: 1.1593 - acc: 0.6620 - val_loss: 1.2696 - val_acc: 0.6561\n",
      "Epoch 33/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.1519 - acc: 0.6636\n",
      "Epoch 00033: val_loss improved from 1.26958 to 1.26546, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 55s 260ms/step - loss: 1.1525 - acc: 0.6634 - val_loss: 1.2655 - val_acc: 0.6574\n",
      "Epoch 34/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.1455 - acc: 0.6650\n",
      "Epoch 00034: val_loss improved from 1.26546 to 1.26177, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 54s 258ms/step - loss: 1.1461 - acc: 0.6648 - val_loss: 1.2618 - val_acc: 0.6587\n",
      "Epoch 35/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 1.1395 - acc: 0.6662\n",
      "Epoch 00035: val_loss improved from 1.26177 to 1.25844, saving model to LaaL_simp_hiddim37-.hdf5\n",
      "210/210 [==============================] - 54s 257ms/step - loss: 1.1401 - acc: 0.6660 - val_loss: 1.2584 - val_acc: 0.6589\n",
      "Epoch 36/100\n",
      "102/210 [=============>................] - ETA: 25s - loss: 1.1130 - acc: 0.6655"
     ]
    }
   ],
   "source": [
    "filepath=\"LaaL_simp_hiddim37-.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "model_simp.fit_generator(train_generator_cond(), \n",
    "                    validation_data=valid_generator_cond(),\n",
    "                    callbacks=callbacks_list,\n",
    "                    steps_per_epoch = n_train, #batch size is inherently 1 via generator\n",
    "                    validation_steps= n_valid,\n",
    "                    epochs=100,\n",
    "                    verbose=1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample trajectory creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposed_traj = [0]\n",
    "visit_count = defaultdict(int)\n",
    "max_allowed_visits = 25\n",
    "\n",
    "while len(proposed_traj) < 1000 and (len(proposed_traj) == 1 or proposed_traj[-1] != 0):\n",
    "    x = np.array(proposed_traj).reshape(1,-1)\n",
    "    #run with s = np.ones(x.shpae) for successful\n",
    "    s = np.ones(x.shape)\n",
    "    for url in reversed(np.argsort(model_cond.predict([x,s])[0,-1])):\n",
    "        if visit_count[url] < max_allowed_visits:\n",
    "            proposed_traj.append(url)\n",
    "            visit_count[url] += 1\n",
    "            break\n",
    "    #predicted = np.argmax(model.predict(x)[0,-1])\n",
    "    print(url)\n",
    "    \n",
    "print(proposed_traj)\n",
    "\n",
    "cert_traj = pd.DataFrame(proposed_traj)\n",
    "cert_traj.to_csv('LaaL_cert_traj_hid_dim30.csv', header = ['certificate trajectory'], index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_traj(sample_traj):\n",
    "    x = np.array(sample_traj[:-1]).reshape(1,-1)\n",
    "    successful = np.ones(x.shape)\n",
    "    unsuccessful = np.ones(x.shape)\n",
    "    cond_prob_successful = np.array(model_cond([x, successful])).reshape(-1, number_of_URL)\n",
    "    cond_prob_unsuccessful = np.array(model_cond([x, unsuccessful])).reshape(-1, number_of_URL)\n",
    "\n",
    "    score_s = []\n",
    "    score_u = []\n",
    "\n",
    "    for choice, prob_s, prob_u in zip(sample_traj[1:], cond_prob_successful, cond_prob_unsuccessful):\n",
    "        score_s.append(np.log(prob_s[choice]))\n",
    "        score_u.append(np.log(prob_u[choice]))\n",
    "    return score_s, score_u\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_success(traj):\n",
    "    score_s, score_u = score_traj(traj)\n",
    "    evidence_s = np.log(success_rate) + np.sum(score_s)\n",
    "    evidence_u = np.log(1 - success_rate) + np.sum(score_u)\n",
    "    prob_of_success = 1 / (1 + np.exp(evidence_u - evidence_s))\n",
    "    return prob_of_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_train, n_train+n_valid):\n",
    "    user = index[i]\n",
    "    traj = trajectories.iloc[user]\n",
    "    ground_truth = status[user]\n",
    "    print(ground_truth, predict_success(traj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # user list key - session level\n",
    "# AM_userList = pd.read_csv('edx-learnerpathway-modeling/data/MITxPRO+AMxB+1T2018/MITxPRO+AMxB+1T2018-stdAgg-userList-key-sessionLevel.csv')\n",
    "# AM_userList\n",
    "\n",
    "# # learning pathway network edge lists - edge list for each student in the course that represent a directed \n",
    "# # transitions networks  of students pathway through the courses content modules.  this is all students.\n",
    "# AM_edgelist = pd.read_csv('edx-learnerpathway-modeling/data/MITxPRO+AMxB+1T2018/MITxPRO+AMxB+1T2018-stdAgg-edges-cohort.csv')\n",
    "# AM_edgelist[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incoming_traj[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([0,1,3,4,5,6])[0,-1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0,1,2,3,4,5,6]).reshape(1,-1)\n",
    "s = np.zeros(x.shape)\n",
    "model2.predict([x,s])[0,-1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort([7,5,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node list of all students' learning pathway networks\n",
    "AM_nodelist = pd.read_csv('edx-learnerpathway-modeling/data/MITxPRO+AMxB+1T2018/MITxPRO+AMxB+1T2018-stdAgg-nodes-cohort.csv')\n",
    "AM_nodelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appendix to the node list that provides a set of XY coordinates to generate a common layout for all networks \n",
    "# produced in the analysis.  force atlas with parameterization <- what is this?\n",
    "AM_node_coord = pd.read_csv('edx-learnerpathway-modeling/data/MITxPRO+AMxB+1T2018/MITxPRO+AMxB+1T2018-stdAgg-nodes-coordinates-FA2.csv')\n",
    "AM_node_coord[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# student identifiers and performance statistics, certification, and enrollment data\n",
    "AM_id_and_performance = pd.read_csv('data/MITxPRO+AMxB+1T2018/MITxPRO-AMxB-1T2018-auth_user-students.csv')\n",
    "AM_id_and_performance['certGrp'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta data includes the course title, run dates\n",
    "LaaL_meta = pd.read_csv('data/MITxPRO+LASERxB1+1T2019/MITxPRO+LASERxB1+1T2019-meta.csv')\n",
    "LaaL_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# complete course structure and module descriptions\n",
    "# list of student identifiers and performance statistics, certification, and enrollment data\n",
    "\n",
    "# LaaL_edgelist = pd.read_csv('data/MITxPRO+LASERxB1+1T2019/MITxPRO+LASERxB1+1T2019-modules.csv')\n",
    "# LaaL_edgelist\n",
    "\n",
    "LaaL_modules = pd.read_csv('data/MITxPRO+LASERxB1+1T2019/MITxPRO+LASERxB1+1T2019-modules00.csv')\n",
    "len(LaaL_modules)\n",
    "LaaL_modules[460:470]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LaaL_edelist = pd.read_csv('data/MITxPRO+LASERxB1+1T2019/MITxPRO+LASERxB1+1T2019-stdAgg-edges.csv')\n",
    "LaaL_edelist[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LaaL_nodelist = pd.read_csv('data/MITxPRO+LASERxB1+1T2019/MITxPRO+LASERxB1+1T2019-stdAgg-nodes.csv')\n",
    "LaaL_nodelist[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LaaL_node_coord = pd.read_csv('data/MITxPRO+LASERxB1+1T2019/MITxPRO+LASERxB1+1T2019-stdAgg-nodes-coordinates-FA2.csv')\n",
    "LaaL_node_coord[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LaaL_id_and_performance = pd.read_csv('data/MITxPRO+LASERxB1+1T2019/MITxPRO-LASERxB1-1T2019-auth_user-students.csv')\n",
    "LaaL_id_and_performance[:5]\n",
    "\n",
    "count = LaaL_id_and_performance[LaaL_id_and_performance['certGrp']== 'Certified (< 65% Grade)']\n",
    "len(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

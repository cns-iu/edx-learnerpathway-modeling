{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, Embedding, Reshape, Multiply\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from data_parsing import load_trajectories\n",
    "from functools import partial, reduce\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "# from glob import glob\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories, status = load_trajectories('data/MITxPRO+AMxB+1T2018/edges', 'data/MITxPRO+AMxB+1T2018/MITxPRO-AMxB-1T2018-auth_user-students.csv')\n",
    "#trajectories, status = load_trajectories('data/MITxPRO+LASERxB1+1T2019/LaaL', 'data/MITxPRO+LASERxB1+1T2019/MITxPRO-LASERxB1-1T2019-auth_user-students.csv')\n",
    "#trajectories = load_trajectories('data/MITxPRO+LASERxB1+1T2019/LaaL')\n",
    "#id_and_performance = pd.read_csv('data/MITxPRO-AMxB-1T2018/MITxPRO-AMxB-1T2018-auth_user-students.csv')\n",
    "#id_and_performance = pd.read_csv('data/MITxPRO+AMxB+1T2018/MITxPRO-AMxB-1T2018-auth_user-students.csv')\n",
    "#id_and_performance.iloc[0]\n",
    "#id_and_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # node list of all students' learning pathway networks\n",
    "# AM_nodelist = pd.read_csv('data/MITxPRO+AMxB+1T2018/MITxPRO+AMxB+1T2018-stdAgg-nodes-cohort.csv')\n",
    "# url_id_to_url_hexname = dict(zip(AM_nodelist['order'], AM_nodelist['id']))\n",
    "# #LaaL_nodelist = pd.read_csv('data/MITxPRO+LASERxB1+1T2019/MITxPRO+LASERxB1+1T2019-stdAgg-nodes.csv')\n",
    "# #url_id_to_url_hexname = dict(zip(LaaL_nodelist['order'], LaaL_nodelist['name']))\n",
    "# url_id_to_url_hexname[0] = 'done with course'\n",
    "# def traj_to_edge_csv(traj, fname):\n",
    "#     edges = []\n",
    "#     urls = [url_id_to_url_hexname[url] for url in traj][1:-1]\n",
    "#     for edge in zip(urls[:-1], urls[1:]):\n",
    "#             # unpack those two items in the in the pair, and convert them from idex id\n",
    "#             edges.append(edge)\n",
    "#     df = pd.DataFrame(data=edges, columns = ['from', 'to'])\n",
    "#     df.to_csv(fname, index=False)\n",
    "# #traj_to_edge_csv(trajectories.iloc[0], 'test_traj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AM_modules = pd.read_csv('data/MITxPRO+AMxB+1T2018/MITxPRO+AMxB+1T2018-modules.txt', sep='\\t', encoding='utf-16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum trajectory identified by number of clicks:  3483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count of students')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "traj_lengths = trajectories.map(len).values\n",
    "plt.hist(traj_lengths)\n",
    "print(\"Maximum trajectory identified by number of clicks: \", max(traj_lengths))\n",
    "plt.title('AM course')\n",
    "plt.xlabel('Learner trajectory length identified by number of clicks')\n",
    "plt.ylabel('Count of students')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data generators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7597701149425288"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = np.arange(len(trajectories))\n",
    "np.random.seed(9)\n",
    "np.random.shuffle(index)\n",
    "\n",
    "incoming_traj = []\n",
    "outgoing_traj = []\n",
    "\n",
    "# this split assumes that we don't need to rebalance for unequal category weights\n",
    "n_valid = int(2*np.sqrt(len(trajectories)))\n",
    "n_train = len(trajectories) - n_valid\n",
    "success_rate = status[index[:n_train]].sum() / n_train\n",
    "\n",
    "for traj in trajectories.values:\n",
    "    incoming_traj.append(np.array(traj[:-1]).reshape(1,-1))\n",
    "    outgoing_traj.append(np.array(traj[1:]).reshape(-1,1))\n",
    "\n",
    "def data_generator(start, stop, use_status):\n",
    "     while True:\n",
    "        for i in range(start, stop):        \n",
    "            x = incoming_traj[index[i]].reshape(1,-1)\n",
    "            s = np.broadcast_to(status[index[i]], x.shape)\n",
    "            y = outgoing_traj[index[i]].reshape(1,-1)\n",
    "            if use_status:\n",
    "                yield [x,s],y\n",
    "            else:\n",
    "                yield x,y\n",
    "\n",
    "train_generator_simp = partial(data_generator, 0, n_train, False)\n",
    "valid_generator_simp = partial(data_generator, n_train, n_train+n_valid, False)\n",
    "train_generator_cond = partial(data_generator, 0, n_train, True)\n",
    "valid_generator_cond = partial(data_generator, n_train, n_train+n_valid, True)\n",
    "success_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 60\n",
    "embedding_dim = 30\n",
    "# turning trajectories into sets of URLs\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "number_of_URL = max(trajectories.sum()) + 1\n",
    "#number_of_URL = 1121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Simple_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "history (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "URL_embedding (Embedding)    (None, None, 30)          22620     \n",
      "_________________________________________________________________\n",
      "LSTM (LSTM)                  (None, None, 60)          21840     \n",
      "_________________________________________________________________\n",
      "Predicted_URL (Dense)        (None, None, 754)         45994     \n",
      "=================================================================\n",
      "Total params: 90,454\n",
      "Trainable params: 90,454\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_ = Input(shape=(None,), name='history')\n",
    "embed = Embedding(number_of_URL, embedding_dim, name='URL_embedding')(input_)\n",
    "\n",
    "rnn = LSTM(hidden_dim, return_sequences=True, name='LSTM')(embed)\n",
    "\n",
    "predicted_URL = Dense(number_of_URL, activation = 'softmax', name='Predicted_URL')(rnn)\n",
    "\n",
    "model_simp = Model(inputs=input_, outputs=predicted_URL, name='Simple_model')\n",
    "model_simp.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "model_simp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conditional_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "history (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "URL_embedding (Embedding)       (None, None, 30)     22620       history[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "status (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "LSTM (LSTM)                     (None, None, 60)     21840       URL_embedding[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Status_embedding (Embedding)    (None, None, 60)     120         status[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, None, 60)     0           LSTM[0][0]                       \n",
      "                                                                 Status_embedding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Predicted_URL (Dense)           (None, None, 754)    45994       multiply[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 90,574\n",
      "Trainable params: 90,574\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_x = Input(shape=(None,), name='history')\n",
    "input_s = Input(shape=(None,), name='status')\n",
    "embed_x = Embedding(number_of_URL, embedding_dim, name='URL_embedding')(input_x)\n",
    "embed_s = Embedding(2, hidden_dim, embeddings_initializer='ones', name='Status_embedding')(input_s)\n",
    "\n",
    "rnn = LSTM(hidden_dim, return_sequences=True, name='LSTM')(embed_x)\n",
    "masked = Multiply()([rnn, embed_s])\n",
    "\n",
    "predicted_URL = Dense(number_of_URL, activation = 'softmax', name='Predicted_URL')(masked)\n",
    "\n",
    "model_cond = Model(inputs=[input_x, input_s], outputs=predicted_URL, name='Conditional_model')\n",
    "model_cond.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "model_cond.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_simp.load_weights('weights/')\n",
    "model_cond.load_weights('weights/AM_cond_hiddim60-.hdf5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-e3ad0b05da92>:10: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 870 steps, validate for 60 steps\n",
      "Epoch 1/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4242 - acc: 0.6292\n",
      "Epoch 00001: val_loss improved from inf to 1.75930, saving model to AM_cond_hiddim60-.hdf5\n",
      "870/870 [==============================] - 304s 350ms/step - loss: 1.4237 - acc: 0.6294 - val_loss: 1.7593 - val_acc: 0.5862\n",
      "Epoch 2/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4215 - acc: 0.6294\n",
      "Epoch 00002: val_loss improved from 1.75930 to 1.75867, saving model to AM_cond_hiddim60-.hdf5\n",
      "870/870 [==============================] - 285s 328ms/step - loss: 1.4210 - acc: 0.6296 - val_loss: 1.7587 - val_acc: 0.5865\n",
      "Epoch 3/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4202 - acc: 0.6297\n",
      "Epoch 00003: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 285s 327ms/step - loss: 1.4197 - acc: 0.6298 - val_loss: 1.7595 - val_acc: 0.5865\n",
      "Epoch 4/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4187 - acc: 0.6298\n",
      "Epoch 00004: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 285s 328ms/step - loss: 1.4182 - acc: 0.6299 - val_loss: 1.7599 - val_acc: 0.5865\n",
      "Epoch 5/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4173 - acc: 0.6300\n",
      "Epoch 00005: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 285s 328ms/step - loss: 1.4168 - acc: 0.6301 - val_loss: 1.7597 - val_acc: 0.5864\n",
      "Epoch 6/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4160 - acc: 0.6302\n",
      "Epoch 00006: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 284s 327ms/step - loss: 1.4155 - acc: 0.6304 - val_loss: 1.7602 - val_acc: 0.5862\n",
      "Epoch 7/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4150 - acc: 0.6301\n",
      "Epoch 00007: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4145 - acc: 0.6302 - val_loss: 1.7608 - val_acc: 0.5868\n",
      "Epoch 8/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4139 - acc: 0.6303\n",
      "Epoch 00008: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 284s 326ms/step - loss: 1.4134 - acc: 0.6305 - val_loss: 1.7615 - val_acc: 0.5862\n",
      "Epoch 9/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4128 - acc: 0.6306\n",
      "Epoch 00009: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 286s 328ms/step - loss: 1.4123 - acc: 0.6307 - val_loss: 1.7606 - val_acc: 0.5867\n",
      "Epoch 10/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4127 - acc: 0.6305\n",
      "Epoch 00010: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 285s 327ms/step - loss: 1.4122 - acc: 0.6307 - val_loss: 1.7608 - val_acc: 0.5868\n",
      "Epoch 11/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4110 - acc: 0.6309\n",
      "Epoch 00011: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 284s 327ms/step - loss: 1.4105 - acc: 0.6311 - val_loss: 1.7608 - val_acc: 0.5871\n",
      "Epoch 12/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4101 - acc: 0.6308\n",
      "Epoch 00012: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 286s 329ms/step - loss: 1.4096 - acc: 0.6309 - val_loss: 1.7615 - val_acc: 0.5865\n",
      "Epoch 13/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4085 - acc: 0.6312\n",
      "Epoch 00013: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 284s 327ms/step - loss: 1.4080 - acc: 0.6313 - val_loss: 1.7619 - val_acc: 0.5866\n",
      "Epoch 14/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4085 - acc: 0.6312\n",
      "Epoch 00014: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 285s 328ms/step - loss: 1.4080 - acc: 0.6313 - val_loss: 1.7618 - val_acc: 0.5866\n",
      "Epoch 15/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4071 - acc: 0.6312\n",
      "Epoch 00015: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 285s 327ms/step - loss: 1.4066 - acc: 0.6313 - val_loss: 1.7629 - val_acc: 0.5866\n",
      "Epoch 16/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4056 - acc: 0.6316\n",
      "Epoch 00016: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 285s 328ms/step - loss: 1.4051 - acc: 0.6318 - val_loss: 1.7637 - val_acc: 0.5864\n",
      "Epoch 17/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4049 - acc: 0.6316\n",
      "Epoch 00017: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 286s 329ms/step - loss: 1.4044 - acc: 0.6317 - val_loss: 1.7629 - val_acc: 0.5868\n",
      "Epoch 18/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4042 - acc: 0.6319\n",
      "Epoch 00018: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 285s 328ms/step - loss: 1.4037 - acc: 0.6320 - val_loss: 1.7640 - val_acc: 0.5864\n",
      "Epoch 19/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4038 - acc: 0.6319\n",
      "Epoch 00019: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 293s 336ms/step - loss: 1.4033 - acc: 0.6321 - val_loss: 1.7646 - val_acc: 0.5864\n",
      "Epoch 20/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4022 - acc: 0.6322\n",
      "Epoch 00020: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 286s 329ms/step - loss: 1.4017 - acc: 0.6323 - val_loss: 1.7644 - val_acc: 0.5864\n",
      "Epoch 21/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4015 - acc: 0.6322\n",
      "Epoch 00021: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 286s 329ms/step - loss: 1.4010 - acc: 0.6324 - val_loss: 1.7654 - val_acc: 0.5859\n",
      "Epoch 22/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4006 - acc: 0.6324\n",
      "Epoch 00022: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 286s 329ms/step - loss: 1.4001 - acc: 0.6325 - val_loss: 1.7659 - val_acc: 0.5867\n",
      "Epoch 23/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3998 - acc: 0.6326\n",
      "Epoch 00023: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 286s 329ms/step - loss: 1.3993 - acc: 0.6327 - val_loss: 1.7660 - val_acc: 0.5859\n",
      "Epoch 24/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3992 - acc: 0.6328\n",
      "Epoch 00024: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 286s 328ms/step - loss: 1.3987 - acc: 0.6330 - val_loss: 1.7660 - val_acc: 0.5867\n",
      "Epoch 25/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3992 - acc: 0.6327\n",
      "Epoch 00025: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 285s 327ms/step - loss: 1.3987 - acc: 0.6328 - val_loss: 1.7667 - val_acc: 0.5862\n",
      "Epoch 26/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3977 - acc: 0.6331\n",
      "Epoch 00026: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 284s 327ms/step - loss: 1.3972 - acc: 0.6333 - val_loss: 1.7672 - val_acc: 0.5862\n",
      "Epoch 27/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3967 - acc: 0.6332\n",
      "Epoch 00027: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 285s 328ms/step - loss: 1.3962 - acc: 0.6334 - val_loss: 1.7669 - val_acc: 0.5866\n",
      "Epoch 28/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3959 - acc: 0.6334\n",
      "Epoch 00028: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 285s 328ms/step - loss: 1.3953 - acc: 0.6335 - val_loss: 1.7682 - val_acc: 0.5860\n",
      "Epoch 29/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3957 - acc: 0.6334\n",
      "Epoch 00029: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 285s 328ms/step - loss: 1.3952 - acc: 0.6335 - val_loss: 1.7688 - val_acc: 0.5858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3953 - acc: 0.6335\n",
      "Epoch 00030: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 282s 324ms/step - loss: 1.3948 - acc: 0.6337 - val_loss: 1.7680 - val_acc: 0.5860\n",
      "Epoch 31/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3955 - acc: 0.6333\n",
      "Epoch 00031: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 282s 325ms/step - loss: 1.3950 - acc: 0.6335 - val_loss: 1.7689 - val_acc: 0.5861\n",
      "Epoch 32/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3932 - acc: 0.6337\n",
      "Epoch 00032: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 282s 325ms/step - loss: 1.3927 - acc: 0.6338 - val_loss: 1.7685 - val_acc: 0.5865\n",
      "Epoch 33/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3927 - acc: 0.6338\n",
      "Epoch 00033: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 282s 324ms/step - loss: 1.3922 - acc: 0.6340 - val_loss: 1.7691 - val_acc: 0.5852\n",
      "Epoch 34/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3920 - acc: 0.6338\n",
      "Epoch 00034: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 283s 325ms/step - loss: 1.3915 - acc: 0.6340 - val_loss: 1.7697 - val_acc: 0.5859\n",
      "Epoch 35/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3913 - acc: 0.6341\n",
      "Epoch 00035: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 282s 324ms/step - loss: 1.3908 - acc: 0.6342 - val_loss: 1.7695 - val_acc: 0.5856\n",
      "Epoch 36/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3912 - acc: 0.6341\n",
      "Epoch 00036: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 282s 324ms/step - loss: 1.3907 - acc: 0.6343 - val_loss: 1.7710 - val_acc: 0.5848\n",
      "Epoch 37/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3903 - acc: 0.6341\n",
      "Epoch 00037: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 281s 323ms/step - loss: 1.3898 - acc: 0.6343 - val_loss: 1.7717 - val_acc: 0.5857\n",
      "Epoch 38/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3895 - acc: 0.6345\n",
      "Epoch 00038: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 282s 324ms/step - loss: 1.3890 - acc: 0.6347 - val_loss: 1.7721 - val_acc: 0.5855\n",
      "Epoch 39/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3894 - acc: 0.6341\n",
      "Epoch 00039: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 283s 326ms/step - loss: 1.3889 - acc: 0.6343 - val_loss: 1.7708 - val_acc: 0.5852\n",
      "Epoch 40/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3881 - acc: 0.6347\n",
      "Epoch 00040: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 282s 324ms/step - loss: 1.3876 - acc: 0.6348 - val_loss: 1.7729 - val_acc: 0.5848\n",
      "Epoch 41/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3881 - acc: 0.6346\n",
      "Epoch 00041: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 282s 324ms/step - loss: 1.3876 - acc: 0.6347 - val_loss: 1.7720 - val_acc: 0.5847\n",
      "Epoch 42/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3876 - acc: 0.6346\n",
      "Epoch 00042: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 282s 324ms/step - loss: 1.3871 - acc: 0.6347 - val_loss: 1.7728 - val_acc: 0.5852\n",
      "Epoch 43/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3864 - acc: 0.6348\n",
      "Epoch 00043: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 282s 325ms/step - loss: 1.3859 - acc: 0.6349 - val_loss: 1.7727 - val_acc: 0.5853\n",
      "Epoch 44/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3877 - acc: 0.6347\n",
      "Epoch 00044: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 282s 324ms/step - loss: 1.3872 - acc: 0.6348 - val_loss: 1.7724 - val_acc: 0.5844\n",
      "Epoch 45/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3855 - acc: 0.6351\n",
      "Epoch 00045: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 282s 324ms/step - loss: 1.3850 - acc: 0.6353 - val_loss: 1.7736 - val_acc: 0.5847\n",
      "Epoch 46/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3847 - acc: 0.6350\n",
      "Epoch 00046: val_loss did not improve from 1.75867\n",
      "870/870 [==============================] - 282s 324ms/step - loss: 1.3842 - acc: 0.6352 - val_loss: 1.7737 - val_acc: 0.5847\n",
      "Epoch 47/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3850 - acc: 0.6349WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.3846 - acc: 0.6351\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e3ad0b05da92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mn_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                     verbose=1,)\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/dataweekends/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dataweekends/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dataweekends/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dataweekends/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                       \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                       \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                       total_epochs=1)\n\u001b[0m\u001b[1;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m    397\u001b[0m                                  prefix='val_')\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dataweekends/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dataweekends/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dataweekends/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dataweekends/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    604\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dataweekends/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dataweekends/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dataweekends/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dataweekends/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dataweekends/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filepath=\"AM_cond_hiddim60-.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "model_cond.fit_generator(train_generator_cond(), \n",
    "                    validation_data=valid_generator_cond(),\n",
    "                    callbacks=callbacks_list,\n",
    "                    steps_per_epoch = n_train, #batch size is inherently 1 via generator\n",
    "                    validation_steps= n_valid,\n",
    "                    epochs=150,\n",
    "                    verbose=1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample trajectory creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposed_traj = [0]\n",
    "visit_count = defaultdict(int)\n",
    "max_allowed_visits = 25\n",
    "\n",
    "while len(proposed_traj) < 1000 and (len(proposed_traj) == 1 or proposed_traj[-1] != 0):\n",
    "    x = np.array(proposed_traj).reshape(1,-1)\n",
    "    #run with s = np.ones(x.shpae) for successful\n",
    "    s = np.zeros(x.shape)\n",
    "    for url in reversed(np.argsort(model_cond.predict([x,s])[0,-1])):\n",
    "    #for url in reversed(np.argsort(model_simp.predict(x)[0,-1])):\n",
    "        if visit_count[url] < max_allowed_visits:\n",
    "            proposed_traj.append(url)\n",
    "            visit_count[url] += 1\n",
    "            break\n",
    "    #predicted = np.argmax(model.predict(x)[0,-1])\n",
    "    print(url)\n",
    "    \n",
    "# print(proposed_traj)\n",
    "\n",
    "# cert_traj = pd.DataFrame(proposed_traj)\n",
    "# cert_traj.to_csv('LaaL_simp_traj_hid_dim37.csv', header = ['simple trajectory'], index = False)\n",
    "traj_to_edge_csv(proposed_traj, 'MITxPRO+AMxB+1T2018_simulated_unsuccessful_Hdim60.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this is to pull out the \"recommended traj\" \n",
    "# proposed_traj = [0]\n",
    "# visit_count = defaultdict(int)\n",
    "# max_allowed_visits = 25\n",
    "\n",
    "# while len(proposed_traj) < 1000 and (len(proposed_traj) == 1 or proposed_traj[-1] != 0):\n",
    "#     x = np.array(proposed_traj).reshape(1,-1)\n",
    "#     #run with s = np.ones(x.shpae) for successful\n",
    "#     s = np.ones(x.shape)\n",
    "#     u = np.zeros(x.shape)\n",
    "#     pred_s = model_cond.predict([x,s])[0,-1]\n",
    "#     pred_u = model_cond.predict([x,u])[0,-1]\n",
    "#     for url in reversed(np.argsort(pred_s - pred_u)):\n",
    "#         if visit_count[url] < max_allowed_visits:\n",
    "#             proposed_traj.append(url)\n",
    "#             visit_count[url] += 1\n",
    "#             break\n",
    "#     #predicted = np.argmax(model.predict(x)[0,-1])\n",
    "#     print(url)\n",
    "    \n",
    "# # print(proposed_traj)\n",
    "\n",
    "# # cert_traj = pd.DataFrame(proposed_traj)\n",
    "# # cert_traj.to_csv('LaaL_simp_traj_hid_dim37.csv', header = ['simple trajectory'], index = False)\n",
    "# traj_to_edge_csv(proposed_traj, 'MITxPRO+AMxB+1T2018_simulated_RECOMMENDEDsuccessful_Hdim60.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_traj(sample_traj):\n",
    "    x = np.array(sample_traj[:-1]).reshape(1,-1)\n",
    "    successful = np.ones(x.shape)\n",
    "    unsuccessful = np.zeros(x.shape)\n",
    "    cond_prob_successful = np.array(model_cond([x, successful])).reshape(-1, number_of_URL)\n",
    "    cond_prob_unsuccessful = np.array(model_cond([x, unsuccessful])).reshape(-1, number_of_URL)\n",
    "\n",
    "    score_s = []\n",
    "    score_u = []\n",
    "\n",
    "    for choice, prob_s, prob_u in zip(sample_traj[1:], cond_prob_successful, cond_prob_unsuccessful):\n",
    "        score_s.append(np.log(prob_s[choice]))\n",
    "        score_u.append(np.log(prob_u[choice]))\n",
    "    return score_s, score_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_success(traj):\n",
    "    score_s, score_u = score_traj(traj)\n",
    "    evidence_s = np.log(success_rate) + np.sum(score_s)\n",
    "    evidence_u = np.log(1 - success_rate) + np.sum(score_u)\n",
    "    prob_of_success = 1 / (1 + np.exp(evidence_u - evidence_s))\n",
    "    return prob_of_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for i in range(n_train, n_train+n_valid):\n",
    "    user = index[i]\n",
    "    traj = trajectories.iloc[user]\n",
    "    y_true.append(status[user])\n",
    "    y_pred.append(predict_success(traj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(zip(y_true,y_pred)))\n",
    "df = pd.DataFrame(confusion_matrix(y_true, np.round(y_pred)))\n",
    "df.columns = ['Predicted unsuccessful', 'Predicted successful']\n",
    "df.index = ['Actual unsuccessful', 'Actual successful']\n",
    "df\n",
    "# columns are predictions, rows are true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     score_s, score_u = score_traj(trajectories.iloc[i])\n",
    "#     score_s = np.array(score_s)\n",
    "#     score_u = np.array(score_u)\n",
    "#     score_delta = (score_s - score_u)[:-1]\n",
    "# #     plt.scatter(trajectories.iloc[i][1:-1], score_delta)\n",
    "# #     plt.xlabel('Learner URL selection')\n",
    "# #     plt.ylabel('Evidence suggesting successful or unsuccessful')\n",
    "# #     plt.title('title')\n",
    "# #     plt.show()\n",
    "    \n",
    "#     traj_pos = np.argmin(score_delta)\n",
    "#     url = trajectories.iloc[i][traj_pos + 1]\n",
    "#     if score_delta[traj_pos] < -0.3:\n",
    "#         print(url)\n",
    "# #     print(url, score_s[traj_pos], score_u[traj_pos])\n",
    "# #     print(trajectories.iloc[i][:traj_pos + 1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url_of_interest = 68\n",
    "# for i in range(100):\n",
    "#     if url_of_interest in trajectories.iloc[i]:\n",
    "#         score_s, score_u = score_traj(trajectories.iloc[i])\n",
    "#         score_s = np.array(score_s)\n",
    "#         score_u = np.array(score_u)\n",
    "#         score_delta = (score_s - score_u)[:-1]\n",
    "        \n",
    "#         url_scores = []\n",
    "#         for j, url in enumerate(trajectories.iloc[i]):\n",
    "#             if url == url_of_interest:\n",
    "#                 url_scores.append(score_delta[j-1])\n",
    "# plt.hist(url_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "auc_score = roc_auc_score(y_true, y_pred)\n",
    "plt.plot(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % (auc_score))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Strategy, Products, Capability Work, and Teams ROC plot')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# fpr = dict()\n",
    "# tpr = dict()\n",
    "# roc_auc = dict()\n",
    "\n",
    "# fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
    "# roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "# # Compute micro-average ROC curve and ROC area\n",
    "# fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), y_pred.ravel())\n",
    "# roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # user list key - session level\n",
    "# AM_userList = pd.read_csv('edx-learnerpathway-modeling/data/MITxPRO+AMxB+1T2018/MITxPRO+AMxB+1T2018-stdAgg-userList-key-sessionLevel.csv')\n",
    "# AM_userList\n",
    "\n",
    "# # learning pathway network edge lists - edge list for each student in the course that represent a directed \n",
    "# # transitions networks  of students pathway through the courses content modules.  this is all students.\n",
    "# AM_edgelist = pd.read_csv('edx-learnerpathway-modeling/data/MITxPRO+AMxB+1T2018/MITxPRO+AMxB+1T2018-stdAgg-edges-cohort.csv')\n",
    "# AM_edgelist[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incoming_traj[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([0,1,3,4,5,6])[0,-1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0,1,2,3,4,5,6]).reshape(1,-1)\n",
    "s = np.zeros(x.shape)\n",
    "model2.predict([x,s])[0,-1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort([7,5,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appendix to the node list that provides a set of XY coordinates to generate a common layout for all networks \n",
    "# produced in the analysis.  force atlas with parameterization <- what is this?\n",
    "AM_node_coord = pd.read_csv('edx-learnerpathway-modeling/data/MITxPRO+AMxB+1T2018/MITxPRO+AMxB+1T2018-stdAgg-nodes-coordinates-FA2.csv')\n",
    "AM_node_coord[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# student identifiers and performance statistics, certification, and enrollment data\n",
    "AM_id_and_performance = pd.read_csv('data/MITxPRO+AMxB+1T2018/MITxPRO-AMxB-1T2018-auth_user-students.csv')\n",
    "AM_id_and_performance['certGrp'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta data includes the course title, run dates\n",
    "LaaL_meta = pd.read_csv('data/MITxPRO+LASERxB1+1T2019/MITxPRO+LASERxB1+1T2019-meta.csv')\n",
    "LaaL_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# complete course structure and module descriptions\n",
    "# list of student identifiers and performance statistics, certification, and enrollment data\n",
    "\n",
    "# LaaL_edgelist = pd.read_csv('data/MITxPRO+LASERxB1+1T2019/MITxPRO+LASERxB1+1T2019-modules.csv')\n",
    "# LaaL_edgelist\n",
    "\n",
    "LaaL_modules = pd.read_csv('data/MITxPRO+LASERxB1+1T2019/MITxPRO+LASERxB1+1T2019-modules00.csv')\n",
    "len(LaaL_modules)\n",
    "LaaL_modules[460:470]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LaaL_edelist = pd.read_csv('data/MITxPRO+LASERxB1+1T2019/MITxPRO+LASERxB1+1T2019-stdAgg-edges.csv')\n",
    "LaaL_edelist[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LaaL_nodelist = pd.read_csv('data/MITxPRO+LASERxB1+1T2019/MITxPRO+LASERxB1+1T2019-stdAgg-nodes.csv')\n",
    "LaaL_nodelist[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AM_nodelist = pd.read_csv('data/MITxPRO+AMxB+1T2018/MITxPRO+AMxB+1T2018-stdAgg-nodes-cohort.csv')\n",
    "AM_nodelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LaaL_node_coord = pd.read_csv('data/MITxPRO+LASERxB1+1T2019/MITxPRO+LASERxB1+1T2019-stdAgg-nodes-coordinates-FA2.csv')\n",
    "LaaL_node_coord[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LaaL_id_and_performance = pd.read_csv('data/MITxPRO+LASERxB1+1T2019/MITxPRO-LASERxB1-1T2019-auth_user-students.csv')\n",
    "LaaL_id_and_performance[:5]\n",
    "\n",
    "count = LaaL_id_and_performance[LaaL_id_and_performance['certGrp']== 'Certified (< 65% Grade)']\n",
    "len(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

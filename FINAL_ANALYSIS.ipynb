{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "private-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_parsing import DataParser\n",
    "from traj_models import LSTM_model\n",
    "#from traj_models import Base_model\n",
    "from preprocessing import DataGenerator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "standard-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AM data\n",
    "data = DataParser('data/MITxPRO+AMxB+1T2018/edges', 'data/MITxPRO+AMxB+1T2018/MITxPRO-AMxB-1T2018-auth_user-students.csv')\n",
    "\n",
    "## LaaL data\n",
    "##data = DataParser('data/MITxPRO+LASERxB1+1T2019/LaaL', 'data/MITxPRO+LASERxB1+1T2019/MITxPRO-LASERxB1-1T2019-auth_user-students.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "minute-trauma",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = DataGenerator(data.trajectories, data.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "buried-redhead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/rsciagli/Documents/Y390_dev/edx-learnerpathway-modeling/traj_models.py:64: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 870 steps, validate for 60 steps\n",
      "Epoch 1/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 4.6365 - acc: 0.1199\n",
      "Epoch 00001: val_loss improved from inf to 3.05823, saving model to AM_test\n",
      "WARNING:tensorflow:From /Users/rsciagli/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 376s 433ms/step - loss: 4.6346 - acc: 0.1202 - val_loss: 3.0582 - val_acc: 0.3087\n",
      "Epoch 2/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 2.4006 - acc: 0.4376\n",
      "Epoch 00002: val_loss improved from 3.05823 to 2.26601, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 323s 371ms/step - loss: 2.4000 - acc: 0.4378 - val_loss: 2.2660 - val_acc: 0.4741\n",
      "Epoch 3/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.9581 - acc: 0.5345\n",
      "Epoch 00003: val_loss improved from 2.26601 to 2.06671, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 295s 339ms/step - loss: 1.9575 - acc: 0.5347 - val_loss: 2.0667 - val_acc: 0.5222\n",
      "Epoch 4/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.8116 - acc: 0.5609\n",
      "Epoch 00004: val_loss improved from 2.06671 to 1.98312, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 291s 335ms/step - loss: 1.8110 - acc: 0.5611 - val_loss: 1.9831 - val_acc: 0.5373\n",
      "Epoch 5/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.7398 - acc: 0.5743\n",
      "Epoch 00005: val_loss improved from 1.98312 to 1.93566, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 292s 336ms/step - loss: 1.7392 - acc: 0.5744 - val_loss: 1.9357 - val_acc: 0.5489\n",
      "Epoch 6/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.6984 - acc: 0.5829\n",
      "Epoch 00006: val_loss improved from 1.93566 to 1.90406, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 291s 335ms/step - loss: 1.6978 - acc: 0.5830 - val_loss: 1.9041 - val_acc: 0.5564\n",
      "Epoch 7/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.6665 - acc: 0.5890\n",
      "Epoch 00007: val_loss improved from 1.90406 to 1.88288, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 290s 333ms/step - loss: 1.6659 - acc: 0.5891 - val_loss: 1.8829 - val_acc: 0.5602\n",
      "Epoch 8/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.6433 - acc: 0.5936\n",
      "Epoch 00008: val_loss improved from 1.88288 to 1.86639, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 292s 336ms/step - loss: 1.6427 - acc: 0.5937 - val_loss: 1.8664 - val_acc: 0.5637\n",
      "Epoch 9/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.6251 - acc: 0.5970\n",
      "Epoch 00009: val_loss improved from 1.86639 to 1.85367, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 290s 334ms/step - loss: 1.6245 - acc: 0.5971 - val_loss: 1.8537 - val_acc: 0.5662\n",
      "Epoch 10/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.6099 - acc: 0.5996\n",
      "Epoch 00010: val_loss improved from 1.85367 to 1.84304, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 292s 336ms/step - loss: 1.6094 - acc: 0.5997 - val_loss: 1.8430 - val_acc: 0.5685\n",
      "Epoch 11/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.5972 - acc: 0.6022\n",
      "Epoch 00011: val_loss improved from 1.84304 to 1.83530, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 293s 337ms/step - loss: 1.5967 - acc: 0.6023 - val_loss: 1.8353 - val_acc: 0.5711\n",
      "Epoch 12/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.5865 - acc: 0.6044\n",
      "Epoch 00012: val_loss improved from 1.83530 to 1.82706, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 293s 337ms/step - loss: 1.5859 - acc: 0.6046 - val_loss: 1.8271 - val_acc: 0.5731\n",
      "Epoch 13/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.5766 - acc: 0.6062\n",
      "Epoch 00013: val_loss improved from 1.82706 to 1.82133, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 292s 336ms/step - loss: 1.5761 - acc: 0.6064 - val_loss: 1.8213 - val_acc: 0.5740\n",
      "Epoch 14/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.5679 - acc: 0.6079\n",
      "Epoch 00014: val_loss improved from 1.82133 to 1.81636, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 338s 388ms/step - loss: 1.5674 - acc: 0.6081 - val_loss: 1.8164 - val_acc: 0.5742\n",
      "Epoch 15/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.5602 - acc: 0.6094\n",
      "Epoch 00015: val_loss improved from 1.81636 to 1.81143, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 297s 341ms/step - loss: 1.5596 - acc: 0.6095 - val_loss: 1.8114 - val_acc: 0.5768\n",
      "Epoch 16/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.5531 - acc: 0.6106\n",
      "Epoch 00016: val_loss improved from 1.81143 to 1.80733, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 291s 335ms/step - loss: 1.5526 - acc: 0.6107 - val_loss: 1.8073 - val_acc: 0.5779\n",
      "Epoch 17/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.5474 - acc: 0.6118\n",
      "Epoch 00017: val_loss improved from 1.80733 to 1.80480, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 292s 335ms/step - loss: 1.5469 - acc: 0.6119 - val_loss: 1.8048 - val_acc: 0.5782\n",
      "Epoch 18/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.5414 - acc: 0.6130\n",
      "Epoch 00018: val_loss improved from 1.80480 to 1.80065, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 293s 337ms/step - loss: 1.5409 - acc: 0.6131 - val_loss: 1.8006 - val_acc: 0.5796\n",
      "Epoch 19/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.5359 - acc: 0.6139\n",
      "Epoch 00019: val_loss improved from 1.80065 to 1.79756, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 291s 334ms/step - loss: 1.5353 - acc: 0.6141 - val_loss: 1.7976 - val_acc: 0.5801\n",
      "Epoch 20/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.5309 - acc: 0.6149\n",
      "Epoch 00020: val_loss improved from 1.79756 to 1.79495, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 294s 338ms/step - loss: 1.5303 - acc: 0.6150 - val_loss: 1.7950 - val_acc: 0.5805\n",
      "Epoch 21/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.5263 - acc: 0.6155\n",
      "Epoch 00021: val_loss improved from 1.79495 to 1.79235, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 292s 335ms/step - loss: 1.5257 - acc: 0.6157 - val_loss: 1.7923 - val_acc: 0.5813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.5220 - acc: 0.6161\n",
      "Epoch 00022: val_loss improved from 1.79235 to 1.79014, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 292s 335ms/step - loss: 1.5214 - acc: 0.6163 - val_loss: 1.7901 - val_acc: 0.5821\n",
      "Epoch 23/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.5180 - acc: 0.6166\n",
      "Epoch 00023: val_loss improved from 1.79014 to 1.78803, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 290s 333ms/step - loss: 1.5174 - acc: 0.6167 - val_loss: 1.7880 - val_acc: 0.5823\n",
      "Epoch 24/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.5143 - acc: 0.6173\n",
      "Epoch 00024: val_loss improved from 1.78803 to 1.78618, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 291s 334ms/step - loss: 1.5138 - acc: 0.6174 - val_loss: 1.7862 - val_acc: 0.5826\n",
      "Epoch 25/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.5108 - acc: 0.6179\n",
      "Epoch 00025: val_loss improved from 1.78618 to 1.78452, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 291s 334ms/step - loss: 1.5102 - acc: 0.6180 - val_loss: 1.7845 - val_acc: 0.5829\n",
      "Epoch 26/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.5073 - acc: 0.6183\n",
      "Epoch 00026: val_loss improved from 1.78452 to 1.78324, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 290s 333ms/step - loss: 1.5067 - acc: 0.6185 - val_loss: 1.7832 - val_acc: 0.5833\n",
      "Epoch 27/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.5041 - acc: 0.6189\n",
      "Epoch 00027: val_loss improved from 1.78324 to 1.78194, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 292s 336ms/step - loss: 1.5035 - acc: 0.6190 - val_loss: 1.7819 - val_acc: 0.5835\n",
      "Epoch 28/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.5010 - acc: 0.6193\n",
      "Epoch 00028: val_loss improved from 1.78194 to 1.78078, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 289s 332ms/step - loss: 1.5005 - acc: 0.6194 - val_loss: 1.7808 - val_acc: 0.5842\n",
      "Epoch 29/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4983 - acc: 0.6196\n",
      "Epoch 00029: val_loss improved from 1.78078 to 1.78035, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 296s 340ms/step - loss: 1.4977 - acc: 0.6198 - val_loss: 1.7804 - val_acc: 0.5837\n",
      "Epoch 30/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4956 - acc: 0.6200\n",
      "Epoch 00030: val_loss improved from 1.78035 to 1.77894, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 289s 332ms/step - loss: 1.4951 - acc: 0.6202 - val_loss: 1.7789 - val_acc: 0.5838\n",
      "Epoch 31/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4927 - acc: 0.6205\n",
      "Epoch 00031: val_loss improved from 1.77894 to 1.77749, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 292s 335ms/step - loss: 1.4922 - acc: 0.6207 - val_loss: 1.7775 - val_acc: 0.5840\n",
      "Epoch 32/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4901 - acc: 0.6207\n",
      "Epoch 00032: val_loss improved from 1.77749 to 1.77713, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 291s 334ms/step - loss: 1.4896 - acc: 0.6209 - val_loss: 1.7771 - val_acc: 0.5846\n",
      "Epoch 33/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4878 - acc: 0.6211\n",
      "Epoch 00033: val_loss improved from 1.77713 to 1.77583, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 290s 334ms/step - loss: 1.4873 - acc: 0.6213 - val_loss: 1.7758 - val_acc: 0.5847\n",
      "Epoch 34/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4854 - acc: 0.6213\n",
      "Epoch 00034: val_loss improved from 1.77583 to 1.77505, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 291s 335ms/step - loss: 1.4849 - acc: 0.6215 - val_loss: 1.7750 - val_acc: 0.5852\n",
      "Epoch 35/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4831 - acc: 0.6217\n",
      "Epoch 00035: val_loss improved from 1.77505 to 1.77394, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 291s 334ms/step - loss: 1.4825 - acc: 0.6219 - val_loss: 1.7739 - val_acc: 0.5852\n",
      "Epoch 36/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4809 - acc: 0.6220\n",
      "Epoch 00036: val_loss improved from 1.77394 to 1.77316, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 291s 334ms/step - loss: 1.4803 - acc: 0.6221 - val_loss: 1.7732 - val_acc: 0.5852\n",
      "Epoch 37/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4787 - acc: 0.6223\n",
      "Epoch 00037: val_loss improved from 1.77316 to 1.77286, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 292s 336ms/step - loss: 1.4781 - acc: 0.6225 - val_loss: 1.7729 - val_acc: 0.5848\n",
      "Epoch 38/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4768 - acc: 0.6226\n",
      "Epoch 00038: val_loss improved from 1.77286 to 1.77236, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 292s 336ms/step - loss: 1.4762 - acc: 0.6228 - val_loss: 1.7724 - val_acc: 0.5843\n",
      "Epoch 39/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4746 - acc: 0.6230\n",
      "Epoch 00039: val_loss improved from 1.77236 to 1.77128, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 295s 339ms/step - loss: 1.4741 - acc: 0.6232 - val_loss: 1.7713 - val_acc: 0.5849\n",
      "Epoch 40/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4726 - acc: 0.6233\n",
      "Epoch 00040: val_loss improved from 1.77128 to 1.77092, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 292s 336ms/step - loss: 1.4721 - acc: 0.6234 - val_loss: 1.7709 - val_acc: 0.5849\n",
      "Epoch 41/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4708 - acc: 0.6235\n",
      "Epoch 00041: val_loss improved from 1.77092 to 1.77004, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 292s 336ms/step - loss: 1.4702 - acc: 0.6237 - val_loss: 1.7700 - val_acc: 0.5848\n",
      "Epoch 42/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4690 - acc: 0.6238\n",
      "Epoch 00042: val_loss improved from 1.77004 to 1.76962, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 292s 335ms/step - loss: 1.4685 - acc: 0.6240 - val_loss: 1.7696 - val_acc: 0.5851\n",
      "Epoch 43/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4673 - acc: 0.6239\n",
      "Epoch 00043: val_loss improved from 1.76962 to 1.76944, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 291s 335ms/step - loss: 1.4667 - acc: 0.6241 - val_loss: 1.7694 - val_acc: 0.5854\n",
      "Epoch 44/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4655 - acc: 0.6242\n",
      "Epoch 00044: val_loss improved from 1.76944 to 1.76884, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 291s 334ms/step - loss: 1.4650 - acc: 0.6244 - val_loss: 1.7688 - val_acc: 0.5854\n",
      "Epoch 45/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4640 - acc: 0.6245\n",
      "Epoch 00045: val_loss improved from 1.76884 to 1.76817, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870/870 [==============================] - 294s 338ms/step - loss: 1.4635 - acc: 0.6247 - val_loss: 1.7682 - val_acc: 0.5855\n",
      "Epoch 46/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4623 - acc: 0.6249\n",
      "Epoch 00046: val_loss improved from 1.76817 to 1.76811, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 291s 334ms/step - loss: 1.4617 - acc: 0.6250 - val_loss: 1.7681 - val_acc: 0.5855\n",
      "Epoch 47/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4606 - acc: 0.6250\n",
      "Epoch 00047: val_loss improved from 1.76811 to 1.76798, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 292s 335ms/step - loss: 1.4601 - acc: 0.6252 - val_loss: 1.7680 - val_acc: 0.5858\n",
      "Epoch 48/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4591 - acc: 0.6253\n",
      "Epoch 00048: val_loss improved from 1.76798 to 1.76765, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 291s 334ms/step - loss: 1.4586 - acc: 0.6254 - val_loss: 1.7676 - val_acc: 0.5856\n",
      "Epoch 49/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4578 - acc: 0.6255\n",
      "Epoch 00049: val_loss improved from 1.76765 to 1.76724, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 292s 336ms/step - loss: 1.4573 - acc: 0.6256 - val_loss: 1.7672 - val_acc: 0.5858\n",
      "Epoch 50/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4562 - acc: 0.6257\n",
      "Epoch 00050: val_loss did not improve from 1.76724\n",
      "870/870 [==============================] - 286s 329ms/step - loss: 1.4557 - acc: 0.6259 - val_loss: 1.7674 - val_acc: 0.5858\n",
      "Epoch 51/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4550 - acc: 0.6259\n",
      "Epoch 00051: val_loss did not improve from 1.76724\n",
      "870/870 [==============================] - 286s 329ms/step - loss: 1.4545 - acc: 0.6260 - val_loss: 1.7673 - val_acc: 0.5860\n",
      "Epoch 52/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4535 - acc: 0.6260\n",
      "Epoch 00052: val_loss improved from 1.76724 to 1.76681, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 289s 333ms/step - loss: 1.4530 - acc: 0.6262 - val_loss: 1.7668 - val_acc: 0.5854\n",
      "Epoch 53/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4527 - acc: 0.6263\n",
      "Epoch 00053: val_loss did not improve from 1.76681\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.4522 - acc: 0.6264 - val_loss: 1.7670 - val_acc: 0.5853\n",
      "Epoch 54/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4512 - acc: 0.6264\n",
      "Epoch 00054: val_loss improved from 1.76681 to 1.76670, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 292s 335ms/step - loss: 1.4507 - acc: 0.6265 - val_loss: 1.7667 - val_acc: 0.5855\n",
      "Epoch 55/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4499 - acc: 0.6267\n",
      "Epoch 00055: val_loss improved from 1.76670 to 1.76655, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 290s 333ms/step - loss: 1.4493 - acc: 0.6269 - val_loss: 1.7665 - val_acc: 0.5851\n",
      "Epoch 56/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4485 - acc: 0.6269\n",
      "Epoch 00056: val_loss improved from 1.76655 to 1.76639, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 290s 334ms/step - loss: 1.4480 - acc: 0.6271 - val_loss: 1.7664 - val_acc: 0.5855\n",
      "Epoch 57/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4478 - acc: 0.6270\n",
      "Epoch 00057: val_loss did not improve from 1.76639\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.4472 - acc: 0.6272 - val_loss: 1.7667 - val_acc: 0.5854\n",
      "Epoch 58/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4463 - acc: 0.6272\n",
      "Epoch 00058: val_loss did not improve from 1.76639\n",
      "870/870 [==============================] - 291s 335ms/step - loss: 1.4458 - acc: 0.6273 - val_loss: 1.7664 - val_acc: 0.5855\n",
      "Epoch 59/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4452 - acc: 0.6275\n",
      "Epoch 00059: val_loss did not improve from 1.76639\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.4446 - acc: 0.6276 - val_loss: 1.7665 - val_acc: 0.5851\n",
      "Epoch 60/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4440 - acc: 0.6277\n",
      "Epoch 00060: val_loss improved from 1.76639 to 1.76629, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 291s 334ms/step - loss: 1.4435 - acc: 0.6278 - val_loss: 1.7663 - val_acc: 0.5854\n",
      "Epoch 61/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4430 - acc: 0.6278\n",
      "Epoch 00061: val_loss did not improve from 1.76629\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4425 - acc: 0.6279 - val_loss: 1.7667 - val_acc: 0.5855\n",
      "Epoch 62/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4419 - acc: 0.6278\n",
      "Epoch 00062: val_loss improved from 1.76629 to 1.76628, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 314s 360ms/step - loss: 1.4414 - acc: 0.6279 - val_loss: 1.7663 - val_acc: 0.5853\n",
      "Epoch 63/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4418 - acc: 0.6279\n",
      "Epoch 00063: val_loss did not improve from 1.76628\n",
      "870/870 [==============================] - 299s 344ms/step - loss: 1.4413 - acc: 0.6280 - val_loss: 1.7671 - val_acc: 0.5855\n",
      "Epoch 64/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4399 - acc: 0.6281\n",
      "Epoch 00064: val_loss improved from 1.76628 to 1.76624, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 335s 386ms/step - loss: 1.4394 - acc: 0.6283 - val_loss: 1.7662 - val_acc: 0.5854\n",
      "Epoch 65/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4389 - acc: 0.6284\n",
      "Epoch 00065: val_loss improved from 1.76624 to 1.76613, saving model to AM_test\n",
      "INFO:tensorflow:Assets written to: AM_test/assets\n",
      "870/870 [==============================] - 329s 378ms/step - loss: 1.4384 - acc: 0.6285 - val_loss: 1.7661 - val_acc: 0.5854\n",
      "Epoch 66/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4379 - acc: 0.6284\n",
      "Epoch 00066: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 310s 356ms/step - loss: 1.4374 - acc: 0.6286 - val_loss: 1.7670 - val_acc: 0.5847\n",
      "Epoch 67/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4370 - acc: 0.6286\n",
      "Epoch 00067: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 345s 397ms/step - loss: 1.4364 - acc: 0.6288 - val_loss: 1.7669 - val_acc: 0.5851\n",
      "Epoch 68/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4360 - acc: 0.6288\n",
      "Epoch 00068: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 300s 345ms/step - loss: 1.4355 - acc: 0.6289 - val_loss: 1.7665 - val_acc: 0.5846\n",
      "Epoch 69/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4351 - acc: 0.6289\n",
      "Epoch 00069: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.4346 - acc: 0.6290 - val_loss: 1.7674 - val_acc: 0.5847\n",
      "Epoch 70/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4342 - acc: 0.6291\n",
      "Epoch 00070: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.4336 - acc: 0.6293 - val_loss: 1.7674 - val_acc: 0.5850\n",
      "Epoch 71/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4336 - acc: 0.6290\n",
      "Epoch 00071: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.4330 - acc: 0.6292 - val_loss: 1.7672 - val_acc: 0.5848\n",
      "Epoch 72/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4327 - acc: 0.6294\n",
      "Epoch 00072: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.4321 - acc: 0.6296 - val_loss: 1.7674 - val_acc: 0.5847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4318 - acc: 0.6295\n",
      "Epoch 00073: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4313 - acc: 0.6296 - val_loss: 1.7678 - val_acc: 0.5847\n",
      "Epoch 74/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4308 - acc: 0.6298\n",
      "Epoch 00074: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.4303 - acc: 0.6300 - val_loss: 1.7677 - val_acc: 0.5849\n",
      "Epoch 75/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4300 - acc: 0.6298\n",
      "Epoch 00075: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4295 - acc: 0.6299 - val_loss: 1.7682 - val_acc: 0.5844\n",
      "Epoch 76/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4300 - acc: 0.6296\n",
      "Epoch 00076: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4295 - acc: 0.6298 - val_loss: 1.7677 - val_acc: 0.5846\n",
      "Epoch 77/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4287 - acc: 0.6299\n",
      "Epoch 00077: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.4282 - acc: 0.6301 - val_loss: 1.7678 - val_acc: 0.5851\n",
      "Epoch 78/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4277 - acc: 0.6302\n",
      "Epoch 00078: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4272 - acc: 0.6304 - val_loss: 1.7687 - val_acc: 0.5849\n",
      "Epoch 79/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4269 - acc: 0.6302\n",
      "Epoch 00079: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4264 - acc: 0.6304 - val_loss: 1.7687 - val_acc: 0.5848\n",
      "Epoch 80/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4264 - acc: 0.6305\n",
      "Epoch 00080: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4258 - acc: 0.6307 - val_loss: 1.7698 - val_acc: 0.5848\n",
      "Epoch 81/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4259 - acc: 0.6303\n",
      "Epoch 00081: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4254 - acc: 0.6305 - val_loss: 1.7689 - val_acc: 0.5851\n",
      "Epoch 82/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4248 - acc: 0.6307\n",
      "Epoch 00082: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4243 - acc: 0.6309 - val_loss: 1.7698 - val_acc: 0.5846\n",
      "Epoch 83/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4243 - acc: 0.6308\n",
      "Epoch 00083: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.4237 - acc: 0.6309 - val_loss: 1.7696 - val_acc: 0.5844\n",
      "Epoch 84/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4236 - acc: 0.6308\n",
      "Epoch 00084: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4231 - acc: 0.6310 - val_loss: 1.7694 - val_acc: 0.5848\n",
      "Epoch 85/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4231 - acc: 0.6309\n",
      "Epoch 00085: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.4226 - acc: 0.6311 - val_loss: 1.7698 - val_acc: 0.5848\n",
      "Epoch 86/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4226 - acc: 0.6310\n",
      "Epoch 00086: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4220 - acc: 0.6312 - val_loss: 1.7697 - val_acc: 0.5848\n",
      "Epoch 87/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4216 - acc: 0.6313\n",
      "Epoch 00087: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4211 - acc: 0.6314 - val_loss: 1.7708 - val_acc: 0.5851\n",
      "Epoch 88/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4206 - acc: 0.6313\n",
      "Epoch 00088: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 289s 332ms/step - loss: 1.4201 - acc: 0.6314 - val_loss: 1.7714 - val_acc: 0.5847\n",
      "Epoch 89/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4202 - acc: 0.6314\n",
      "Epoch 00089: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4197 - acc: 0.6316 - val_loss: 1.7707 - val_acc: 0.5851\n",
      "Epoch 90/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4197 - acc: 0.6313\n",
      "Epoch 00090: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4192 - acc: 0.6315 - val_loss: 1.7710 - val_acc: 0.5852\n",
      "Epoch 91/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4198 - acc: 0.6315\n",
      "Epoch 00091: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.4193 - acc: 0.6316 - val_loss: 1.7712 - val_acc: 0.5855\n",
      "Epoch 92/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4182 - acc: 0.6316\n",
      "Epoch 00092: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4177 - acc: 0.6318 - val_loss: 1.7718 - val_acc: 0.5850\n",
      "Epoch 93/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4176 - acc: 0.6318\n",
      "Epoch 00093: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.4171 - acc: 0.6320 - val_loss: 1.7719 - val_acc: 0.5852\n",
      "Epoch 94/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4170 - acc: 0.6318\n",
      "Epoch 00094: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.4164 - acc: 0.6320 - val_loss: 1.7722 - val_acc: 0.5847\n",
      "Epoch 95/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4167 - acc: 0.6320\n",
      "Epoch 00095: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4162 - acc: 0.6321 - val_loss: 1.7729 - val_acc: 0.5847\n",
      "Epoch 96/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4161 - acc: 0.6319\n",
      "Epoch 00096: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4156 - acc: 0.6321 - val_loss: 1.7725 - val_acc: 0.5845\n",
      "Epoch 97/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4164 - acc: 0.6319\n",
      "Epoch 00097: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.4158 - acc: 0.6321 - val_loss: 1.7730 - val_acc: 0.5854\n",
      "Epoch 98/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4149 - acc: 0.6322\n",
      "Epoch 00098: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 289s 332ms/step - loss: 1.4144 - acc: 0.6323 - val_loss: 1.7724 - val_acc: 0.5854\n",
      "Epoch 99/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4141 - acc: 0.6323\n",
      "Epoch 00099: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.4136 - acc: 0.6324 - val_loss: 1.7724 - val_acc: 0.5851\n",
      "Epoch 100/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4137 - acc: 0.6324\n",
      "Epoch 00100: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.4132 - acc: 0.6325 - val_loss: 1.7725 - val_acc: 0.5856\n",
      "Epoch 101/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4132 - acc: 0.6324\n",
      "Epoch 00101: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.4127 - acc: 0.6326 - val_loss: 1.7734 - val_acc: 0.5852\n",
      "Epoch 102/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4142 - acc: 0.6321\n",
      "Epoch 00102: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4137 - acc: 0.6323 - val_loss: 1.7741 - val_acc: 0.5850\n",
      "Epoch 103/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4124 - acc: 0.6325\n",
      "Epoch 00103: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.4119 - acc: 0.6326 - val_loss: 1.7735 - val_acc: 0.5855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4114 - acc: 0.6327\n",
      "Epoch 00104: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.4109 - acc: 0.6329 - val_loss: 1.7737 - val_acc: 0.5851\n",
      "Epoch 105/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4110 - acc: 0.6326\n",
      "Epoch 00105: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4104 - acc: 0.6327 - val_loss: 1.7745 - val_acc: 0.5851\n",
      "Epoch 106/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4108 - acc: 0.6330\n",
      "Epoch 00106: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4103 - acc: 0.6331 - val_loss: 1.7745 - val_acc: 0.5851\n",
      "Epoch 107/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4103 - acc: 0.6329\n",
      "Epoch 00107: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4098 - acc: 0.6331 - val_loss: 1.7748 - val_acc: 0.5853\n",
      "Epoch 108/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4099 - acc: 0.6328\n",
      "Epoch 00108: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 332s 382ms/step - loss: 1.4094 - acc: 0.6330 - val_loss: 1.7757 - val_acc: 0.5849\n",
      "Epoch 109/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4090 - acc: 0.6331\n",
      "Epoch 00109: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 289s 332ms/step - loss: 1.4084 - acc: 0.6332 - val_loss: 1.7748 - val_acc: 0.5855\n",
      "Epoch 110/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4084 - acc: 0.6334\n",
      "Epoch 00110: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4079 - acc: 0.6335 - val_loss: 1.7752 - val_acc: 0.5853\n",
      "Epoch 111/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4081 - acc: 0.6333\n",
      "Epoch 00111: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.4076 - acc: 0.6335 - val_loss: 1.7770 - val_acc: 0.5845\n",
      "Epoch 112/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4089 - acc: 0.6330\n",
      "Epoch 00112: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4084 - acc: 0.6331 - val_loss: 1.7757 - val_acc: 0.5850\n",
      "Epoch 113/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4088 - acc: 0.6333\n",
      "Epoch 00113: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4083 - acc: 0.6335 - val_loss: 1.7768 - val_acc: 0.5847\n",
      "Epoch 114/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4073 - acc: 0.6333\n",
      "Epoch 00114: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 286s 329ms/step - loss: 1.4068 - acc: 0.6334 - val_loss: 1.7763 - val_acc: 0.5855\n",
      "Epoch 115/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4065 - acc: 0.6335\n",
      "Epoch 00115: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4059 - acc: 0.6337 - val_loss: 1.7769 - val_acc: 0.5852\n",
      "Epoch 116/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4057 - acc: 0.6336\n",
      "Epoch 00116: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4052 - acc: 0.6337 - val_loss: 1.7773 - val_acc: 0.5849\n",
      "Epoch 117/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4065 - acc: 0.6336\n",
      "Epoch 00117: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4060 - acc: 0.6337 - val_loss: 1.7784 - val_acc: 0.5851\n",
      "Epoch 118/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4066 - acc: 0.6334\n",
      "Epoch 00118: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4060 - acc: 0.6335 - val_loss: 1.7775 - val_acc: 0.5852\n",
      "Epoch 119/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4047 - acc: 0.6339\n",
      "Epoch 00119: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4042 - acc: 0.6340 - val_loss: 1.7785 - val_acc: 0.5853\n",
      "Epoch 120/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4041 - acc: 0.6339\n",
      "Epoch 00120: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4036 - acc: 0.6341 - val_loss: 1.7791 - val_acc: 0.5854\n",
      "Epoch 121/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4035 - acc: 0.6341\n",
      "Epoch 00121: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4030 - acc: 0.6343 - val_loss: 1.7797 - val_acc: 0.5854\n",
      "Epoch 122/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4033 - acc: 0.6340\n",
      "Epoch 00122: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4028 - acc: 0.6342 - val_loss: 1.7795 - val_acc: 0.5859\n",
      "Epoch 123/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4032 - acc: 0.6342\n",
      "Epoch 00123: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.4027 - acc: 0.6343 - val_loss: 1.7804 - val_acc: 0.5853\n",
      "Epoch 124/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4028 - acc: 0.6342\n",
      "Epoch 00124: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4023 - acc: 0.6344 - val_loss: 1.7802 - val_acc: 0.5853\n",
      "Epoch 125/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4034 - acc: 0.6340\n",
      "Epoch 00125: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 289s 332ms/step - loss: 1.4029 - acc: 0.6341 - val_loss: 1.7805 - val_acc: 0.5849\n",
      "Epoch 126/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4028 - acc: 0.6343\n",
      "Epoch 00126: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.4022 - acc: 0.6344 - val_loss: 1.7809 - val_acc: 0.5855\n",
      "Epoch 127/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4018 - acc: 0.6342\n",
      "Epoch 00127: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.4012 - acc: 0.6343 - val_loss: 1.7804 - val_acc: 0.5854\n",
      "Epoch 128/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4012 - acc: 0.6342\n",
      "Epoch 00128: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 332ms/step - loss: 1.4006 - acc: 0.6343 - val_loss: 1.7817 - val_acc: 0.5851\n",
      "Epoch 129/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4004 - acc: 0.6345\n",
      "Epoch 00129: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 290s 333ms/step - loss: 1.3998 - acc: 0.6346 - val_loss: 1.7816 - val_acc: 0.5854\n",
      "Epoch 130/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4011 - acc: 0.6343\n",
      "Epoch 00130: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 329ms/step - loss: 1.4006 - acc: 0.6345 - val_loss: 1.7808 - val_acc: 0.5840\n",
      "Epoch 131/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4003 - acc: 0.6348\n",
      "Epoch 00131: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.3997 - acc: 0.6349 - val_loss: 1.7821 - val_acc: 0.5847\n",
      "Epoch 132/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3997 - acc: 0.6346\n",
      "Epoch 00132: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.3991 - acc: 0.6347 - val_loss: 1.7830 - val_acc: 0.5852\n",
      "Epoch 133/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.4000 - acc: 0.6346\n",
      "Epoch 00133: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.3995 - acc: 0.6348 - val_loss: 1.7825 - val_acc: 0.5846\n",
      "Epoch 134/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "869/870 [============================>.] - ETA: 0s - loss: 1.3989 - acc: 0.6347\n",
      "Epoch 00134: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.3984 - acc: 0.6348 - val_loss: 1.7827 - val_acc: 0.5853\n",
      "Epoch 135/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3980 - acc: 0.6349\n",
      "Epoch 00135: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.3974 - acc: 0.6350 - val_loss: 1.7849 - val_acc: 0.5848\n",
      "Epoch 136/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3985 - acc: 0.6349\n",
      "Epoch 00136: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.3980 - acc: 0.6350 - val_loss: 1.7835 - val_acc: 0.5854\n",
      "Epoch 137/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3976 - acc: 0.6350\n",
      "Epoch 00137: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 329ms/step - loss: 1.3971 - acc: 0.6351 - val_loss: 1.7845 - val_acc: 0.5852\n",
      "Epoch 138/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3979 - acc: 0.6349\n",
      "Epoch 00138: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.3974 - acc: 0.6351 - val_loss: 1.7895 - val_acc: 0.5841\n",
      "Epoch 139/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3984 - acc: 0.6348\n",
      "Epoch 00139: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.3979 - acc: 0.6350 - val_loss: 1.7845 - val_acc: 0.5856\n",
      "Epoch 140/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3975 - acc: 0.6349\n",
      "Epoch 00140: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 330ms/step - loss: 1.3969 - acc: 0.6350 - val_loss: 1.7864 - val_acc: 0.5855\n",
      "Epoch 141/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3966 - acc: 0.6351\n",
      "Epoch 00141: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.3961 - acc: 0.6352 - val_loss: 1.7862 - val_acc: 0.5852\n",
      "Epoch 142/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3963 - acc: 0.6352\n",
      "Epoch 00142: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.3958 - acc: 0.6354 - val_loss: 1.7868 - val_acc: 0.5848\n",
      "Epoch 143/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3958 - acc: 0.6352\n",
      "Epoch 00143: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.3953 - acc: 0.6353 - val_loss: 1.7852 - val_acc: 0.5848\n",
      "Epoch 144/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3964 - acc: 0.6353\n",
      "Epoch 00144: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.3958 - acc: 0.6354 - val_loss: 1.7863 - val_acc: 0.5846\n",
      "Epoch 145/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3949 - acc: 0.6355\n",
      "Epoch 00145: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.3944 - acc: 0.6356 - val_loss: 1.7866 - val_acc: 0.5845\n",
      "Epoch 146/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3948 - acc: 0.6355\n",
      "Epoch 00146: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 331ms/step - loss: 1.3943 - acc: 0.6356 - val_loss: 1.7873 - val_acc: 0.5844\n",
      "Epoch 147/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3949 - acc: 0.6353\n",
      "Epoch 00147: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.3944 - acc: 0.6354 - val_loss: 1.7868 - val_acc: 0.5847\n",
      "Epoch 148/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3952 - acc: 0.6353\n",
      "Epoch 00148: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.3947 - acc: 0.6355 - val_loss: 1.7865 - val_acc: 0.5852\n",
      "Epoch 149/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3944 - acc: 0.6354\n",
      "Epoch 00149: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 288s 330ms/step - loss: 1.3938 - acc: 0.6355 - val_loss: 1.7880 - val_acc: 0.5846\n",
      "Epoch 150/150\n",
      "869/870 [============================>.] - ETA: 0s - loss: 1.3935 - acc: 0.6357\n",
      "Epoch 00150: val_loss did not improve from 1.76613\n",
      "870/870 [==============================] - 287s 330ms/step - loss: 1.3929 - acc: 0.6359 - val_loss: 1.7868 - val_acc: 0.5848\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_model(generator.num_URLs)\n",
    "model.train(generator, 'AM_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1000   # Do 1000 predictions to estimate uncertainty\n",
    "predictions = np.array([model.predict(valid_generator())] for _ in range(T))\n",
    "\n",
    "pred_mean = results.mean(axis=0)\n",
    "pre_std   = results.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "refined-cowboy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/rsciagli/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-0f61e39efd12>\", line 5, in <module>\n",
      "    x.append(ele[0])\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rsciagli/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rsciagli/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/rsciagli/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/rsciagli/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/rsciagli/opt/anaconda3/envs/learning_analytics/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/rsciagli/opt/anaconda3/envs/learning_analytics/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/rsciagli/opt/anaconda3/envs/learning_analytics/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/rsciagli/opt/anaconda3/envs/learning_analytics/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/Users/rsciagli/opt/anaconda3/envs/learning_analytics/lib/python3.7/posixpath.py\", line 396, in realpath\n",
      "    return abspath(path)\n",
      "  File \"/Users/rsciagli/opt/anaconda3/envs/learning_analytics/lib/python3.7/posixpath.py\", line 385, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/Users/rsciagli/opt/anaconda3/envs/learning_analytics/lib/python3.7/posixpath.py\", line 362, in normpath\n",
      "    if comp in (empty, dot):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-0f61e39efd12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2047\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1436\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             )\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1193\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "train_generator, valid_generator = generator.build_generators(False)\n",
    "x = []\n",
    "y = []\n",
    "for ele in valid_generator():\n",
    "    x.append(ele[0])\n",
    "    y.append(ele[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x),len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "still-locator",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ac88c907cf4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, standardize_function, workers, use_multiprocessing, max_queue_size, **kwargs)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m     dataset = dataset_ops.DatasetV2.from_generator(\n\u001b[0;32m--> 764\u001b[0;31m         generator_fn, nested_dtypes, output_shapes=nested_shape)\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstandardize_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_generator\u001b[0;34m(generator, output_types, output_shapes, args)\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[0;31m# versions of the returned dataset to be created, because it forces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m     \u001b[0;31m# the generation of a new ID for each version.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mid_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_map_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mflat_map\u001b[0;34m(self, map_func)\u001b[0m\n\u001b[1;32m   1613\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1614\u001b[0m     \"\"\"\n\u001b[0;32m-> 1615\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFlatMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1617\u001b[0m   def interleave(self,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func)\u001b[0m\n\u001b[1;32m   3956\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3957\u001b[0m     self._map_func = StructuredFunctionWrapper(\n\u001b[0;32m-> 3958\u001b[0;31m         map_func, self._transformation_name(), dataset=input_dataset)\n\u001b[0m\u001b[1;32m   3959\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3960\u001b[0m       raise TypeError(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3145\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3146\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2393\u001b[0m     \u001b[0;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[0;32m-> 2395\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2396\u001b[0m     \u001b[0;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m     \u001b[0;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3138\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3139\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3080\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m           optional_features=optional_features)\n\u001b[1;32m    233\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_whitelisted_for_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    328\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mflat_map_fn\u001b[0;34m(dummy_arg)\u001b[0m\n\u001b[1;32m    862\u001b[0m       \u001b[0;31m# more elements.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m       return _GeneratorDataset(dummy_arg, get_iterator_id_fn, generator_next_fn,\n\u001b[0;32m--> 864\u001b[0;31m                                finalize_fn)\n\u001b[0m\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m     \u001b[0;31m# A single-element dataset that, each time it is evaluated, contains a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, init_args, init_func, next_func, finalize_func)\u001b[0m\n\u001b[1;32m   3214\u001b[0m         \u001b[0minit_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3216\u001b[0;31m         input_structure=self._init_structure)\n\u001b[0m\u001b[1;32m   3217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3218\u001b[0m     self._next_func = StructuredFunctionWrapper(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3145\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3146\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2393\u001b[0m     \u001b[0;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[0;32m-> 2395\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2396\u001b[0m     \u001b[0;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m     \u001b[0;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    981\u001b[0m       \u001b[0;31m# TensorArrays and `None`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m       func_outputs = nest.map_structure(convert, func_outputs,\n\u001b[0;32m--> 983\u001b[0;31m                                         expand_composites=True)\n\u001b[0m\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m       \u001b[0mcheck_mutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_args_before\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    943\u001b[0m               (str(python_func), type(x)))\n\u001b[1;32m    944\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0madd_control_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeps_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36mmark_as_return\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;31m# of a new identity operation that the stateful operations definitely don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# depend on.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_returned_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m   \u001b[0;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_handle_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   3827\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3828\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m-> 3829\u001b[0;31m         \"Identity\", input=input, name=name)\n\u001b[0m\u001b[1;32m   3830\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3831\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    740\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    741\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    593\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3311\u001b[0m     \u001b[0;31m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3312\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3313\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3314\u001b[0m       ret = Operation(\n\u001b[1;32m   3315\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/util/lock_util.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/util/lock_util.py\u001b[0m in \u001b[0;36macquire\u001b[0;34m(self, group_id)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_another_group_active\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_member_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning_analytics/lib/python3.7/site-packages/tensorflow_core/python/util/lock_util.py\u001b[0m in \u001b[0;36m_another_group_active\u001b[0;34m(self, group_id)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_another_group_active\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     return any(\n\u001b[0;32m--> 108\u001b[0;31m         c > 0 for g, c in enumerate(self._group_member_counts) if g != group_id)\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_validate_group_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.model.predict(valid_generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.model.predict(x[0])\n",
    "accuracy_score(y[0], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-shift",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.model.predict(x[0])\n",
    "url_pred = np.argmax(pred, axis=-1)\n",
    "np.sum(url_pred==y[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-affiliate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
